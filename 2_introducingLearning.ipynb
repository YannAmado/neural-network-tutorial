{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b3429c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random as rd\n",
    "from keras.datasets import mnist\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56fa66",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Network:\n",
    "    \"\"\"\n",
    "    The main object we're going to use accross this notebook\n",
    "    It's a neural network that takes as input a list of \n",
    "    layers nodes\n",
    "    \n",
    "    Ex: [2, 3, 1] is a 3 layer network, with 2 neurons of input, 3 neurons \n",
    "    in the hidden layer and 1 for the output layer\n",
    "    \n",
    "    Supposedly it can take more than just 3 layers but I didnt test it\n",
    "    \n",
    "    It initializes an object with the proper weights, biases, activations and z\n",
    "    based on the layers list. It also has the layers list and the number of layers\n",
    "    \n",
    "    The weights and biases initialized following a Gaussian of mean 1\n",
    "    \"\"\"\n",
    "    def __init__(self, layers: list):        \n",
    "        np.random.seed(42)        \n",
    "        b = []\n",
    "        w = []\n",
    "        a = []\n",
    "        z = []\n",
    "        for l in range(0, len(layers)):\n",
    "            # skipping one layer for the weights and biases\n",
    "            if (l+1) < len(layers):\n",
    "                b.append(np.random.normal(loc=0, scale=1,size=layers[l+1]))\n",
    "                w.append(np.random.normal(loc=0,scale=1,size=[layers[l],layers[l+1]]))\n",
    "            a.append(np.zeros(layers[l]))\n",
    "            z.append(np.zeros(layers[l]))\n",
    "    \n",
    "        # b[i][j] -> \"i\" is which layer, \"j\" which neuron\n",
    "        # w[i][j][k] -> \"i\" is which layer, \"j\" which neuron of the first layer, \"k\" which neuron of the second layer\n",
    "        self.b = b\n",
    "        self.w = w\n",
    "        self.a = a\n",
    "        self.z = z\n",
    "        self.nLayers = len(layers)\n",
    "        self.layers = layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3223b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(n: float):\n",
    "    return 1.0/(1.0+np.exp(-n))\n",
    "\n",
    "def sigmoid_derivative(n: float):\n",
    "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
    "    return sigmoid(n)*(1-sigmoid(n))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81979df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feedForward(net: Network) -> Network:\n",
    "    \"\"\"\n",
    "    Feedforwading the activations to the next layer\n",
    "    \n",
    "    It will take as input the network already with the input image as the activation \n",
    "    on the first layer and then feedforward to the next layrse\n",
    "    \n",
    "    It returns the network with all the activations set\n",
    "    \"\"\"\n",
    "    \n",
    "    # resetting the activations as to not take any info from the activation of\n",
    "    # the previous number while maintanin the first activation\n",
    "    for i in range(1, net.nLayers):\n",
    "        net.z[i] = np.zeros(net.layers[i])\n",
    "        net.a[i] = np.zeros(net.layers[i])\n",
    "    for l in range(0, net.nLayers-1):\n",
    "        for receivingNeuron in range(net.layers[l+1]):\n",
    "            for givingNeuron in range(net.layers[l]):\n",
    "                net.z[l+1][receivingNeuron] += net.a[l][givingNeuron] * net.w[l][givingNeuron][receivingNeuron]\n",
    "            net.z[l+1][receivingNeuron] += net.b[l][receivingNeuron]\n",
    "            net.a[l+1][receivingNeuron] = sigmoid(net.z[l+1][receivingNeuron])\n",
    "\n",
    "            \n",
    "    return net\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e376769",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCostVector(network: Network, rightNumber):\n",
    "    lastLayer = -1\n",
    "    cost = np.zeros(network.nOutputs)\n",
    "    for i in range(network.nOutputs):\n",
    "        if i+1 == rightNumber:\n",
    "            cost[i] = (network.activations[lastLayer][i] - 1)**2 \n",
    "        else:\n",
    "            cost[i] = (network.activations[lastLayer][i] - 0)**2 \n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f40fd093",
   "metadata": {},
   "outputs": [],
   "source": [
    "def findCostDerivative(network: Network, rightNumber):\n",
    "    lastLayer = -1\n",
    "    cost = np.zeros(network.nOutputs)\n",
    "    for i in range(network.nOutputs):\n",
    "        if i == rightNumber:\n",
    "            cost[i] = 2*(network.activations[lastLayer][i] - 1)\n",
    "        else:\n",
    "            cost[i] = 2*(network.activations[lastLayer][i] - 0)\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e29a12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setActivations(network: Network, img):\n",
    "        #passing the inputs to our network\n",
    "        for i in range(28):\n",
    "            for j in range(28):\n",
    "                network.activations[0][28*i + j] = img[i][j]\n",
    "        return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "781948d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation(network: Network, xBatch, yBatch, batchSize, learningRate):\n",
    "    eta = learningRate\n",
    "    \n",
    "    size = []\n",
    "    size.append(network.nInputs)\n",
    "    for i in range(network.nHiddenLayers):\n",
    "        size.append(network.nNeuronsPerHL)\n",
    "    size.append(network.nOutputs)\n",
    "    delta_l = [np.zeros(s) for s in size[:None]]\n",
    "    # recreating the shape of the biases and weights\n",
    "    nablaB = np.empty_like(network.biases)\n",
    "    nablaW = np.empty_like(network.weights)\n",
    "    #-1 because array and -1 because the last layer will not be iterated and -1 because the first layer has no bias\n",
    "    for img in range(batchSize):\n",
    "        network = setActivations(network, xBatch[img])\n",
    "        network = feedforward(network)\n",
    "        delta_l[-1] = 2*findCostDerivative(network, yBatch[img])*sigmoidDerivative(network.zActivations[-1])\n",
    "        \n",
    "        # finding dC/dW and dC/dB\n",
    "        for l in range(network.totalLayers-2, -1, -1): \n",
    "            if l == 0:\n",
    "                delta_l[l] += np.dot(network.weights[l].T, delta_l[l+1])*sigmoidDerivative(network.zActivations[l])\n",
    "                nablaB[l] += delta_l[l]\n",
    "                nablaW[l] += np.dot(network.activations[l-1], delta_l[l])\n",
    "    print(f\"delta 0: {delta_l[0,0]},\" \n",
    "              f\"delta 1: {delta_l[1,0]},\" \n",
    "              f\"delta 2: {delta_l[2,0]}\")\n",
    "    \n",
    "    # taking the averages\n",
    "    nablaB = nablaB/batchSize\n",
    "    nablaW = nablaW/batchSize\n",
    "    # adjusting the network\n",
    "    for i in range(network.totalLayers-2):\n",
    "        network.biases[i] = network.biases[i] - eta*nablaB[i]\n",
    "        network.weights[i] = network.weights[i] - eta*nablaW[i]\n",
    "    return network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "10332287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD(network: Network, trainX, trainY, batchSize, epochs, learningRate):\n",
    "    \n",
    "    # shuffling\n",
    "    trainingImages = list(zip(trainX, trainY))\n",
    "    random.shuffle(trainingImages)\n",
    "    trainX, trainY = zip(*trainingImages)\n",
    "\n",
    "    for currentEpoch in range(epochs):\n",
    "        yBatch = trainY[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        xBatch = trainX[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        # print(\"before: \", network.weights[0,0][0], network.biases[0,0])\n",
    "        network = backPropagation(network, xBatch, yBatch, batchSize, learningRate)\n",
    "        # print(\"after: \", network.weights[0,0][0], network.biases[0,0])\n",
    "        hits = 0\n",
    "        misses = 0\n",
    "        numbersThinked = np.zeros(10)\n",
    "        trainXX = trainX[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        trainYY = trainY[currentEpoch*batchSize: (currentEpoch + 1)*batchSize]\n",
    "        for imgX, imgY in zip(trainXX, trainYY):\n",
    "            network = setActivations(network, imgX)\n",
    "            network = feedforward(network)\n",
    "            numberNetworkThinks, certainty = classify(network)\n",
    "            numbersThinked[numberNetworkThinks] += 1 \n",
    "            if numberNetworkThinks == imgY:\n",
    "                hits += 1\n",
    "            else:\n",
    "                misses += 1\n",
    "        acc = hits/misses\n",
    "        print(f'epoch {currentEpoch+1}, accuracy = {acc}, numbers guessed = {numbersThinked}')\n",
    "    return network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7696f673",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "<ipython-input-1-1ddd3759b107>:31: RuntimeWarning: overflow encountered in exp\n",
      "  sigNumber = 1/(1 + np.exp(-number))\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (30,784) and (30,) not aligned: 784 (dim 1) != 30 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-f5641489c7c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmisses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnTrainingImages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-3e553726a593>\u001b[0m in \u001b[0;36mSGD\u001b[1;34m(network, trainX, trainY, batchSize, epochs, learningRate)\u001b[0m\n\u001b[0;32m     10\u001b[0m         \u001b[0mxBatch\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrainX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcurrentEpoch\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mcurrentEpoch\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatchSize\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[1;31m# print(\"before: \", network.weights[0,0][0], network.biases[0,0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[0mnetwork\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myBatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlearningRate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m         \u001b[1;31m# print(\"after: \", network.weights[0,0][0], network.biases[0,0])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m         \u001b[0mhits\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-9c1daba8af87>\u001b[0m in \u001b[0;36mbackPropagation\u001b[1;34m(network, xBatch, yBatch, batchSize, learningRate)\u001b[0m\n\u001b[0;32m     20\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtotalLayers\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0ml\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m                 \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0msigmoidDerivative\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzActivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0mnablaB\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mnablaW\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelta_l\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: shapes (30,784) and (30,) not aligned: 784 (dim 1) != 30 (dim 0)"
     ]
    }
   ],
   "source": [
    "network = Network(28*28, 1, 30, 10)\n",
    "hits = 0\n",
    "misses = 0\n",
    "nTrainingImages = trainX.shape[0]\n",
    "network = SGD(network, trainX, trainY, batchSize=100, epochs=100, learningRate = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee91fb1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
